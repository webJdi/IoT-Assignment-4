{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "699648d0",
   "metadata": {},
   "source": [
    "# Long Short Term Memory Networks for IoT Prediction\n",
    "\n",
    "RNNs and LSTM models are very popular neural network architectures when working with sequential data, since they both carry some \"memory\" of previous inputs when predicting the next output. In this assignment we will continue to work with the Household Electricity Consumption dataset and use an LSTM model to predict the Global Active Power (GAP) from a sequence of previous GAP readings. You will build one model following the directions in this notebook closely, then you will be asked to make changes to that original model and analyze the effects that they had on the model performance. You will also be asked to compare the performance of your LSTM model to the linear regression predictor that you built in last week's assignment.\n",
    "\n",
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "When you save your notebook as a pdf, make sure that all cell output is visible (even error messages) as this will aid your instructor in grading your work.\n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96422f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Setting seed for reproducibility\n",
    "np.random.seed(1234)  \n",
    "PYTHONHASHSEED = 0\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb722f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this cell to import additional libraries or define helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d897e4",
   "metadata": {},
   "source": [
    "## Load and prepare your data\n",
    "\n",
    "We'll once again be using the cleaned household electricity consumption data from the previous two assignments. I recommend saving your dataset by running df.to_csv(\"filename\") at the end of assignment 2 so that you don't have to re-do your cleaning steps. If you are not confident in your own cleaning steps, you may ask your instructor for a cleaned version of the data. You will not be graded on the cleaning steps in this assignment, but some functions may not work if you use the raw data.\n",
    "\n",
    "Unlike when using Linear Regression to make our predictions for Global Active Power (GAP), LSTM requires that we have a pre-trained model when our predictive software is shipped (the ability to iterate on the model after it's put into production is another question for another day). Thus, we will train the model on a segment of our data and then measure its performance on simulated streaming data another segment of the data. Our dataset is very large, so for speed's sake, we will limit ourselves to 1% of the entire dataset.\n",
    "\n",
    "**TODO: Import your data, select the a random 1% of the dataset, and then split it 80/20 into training and validation sets (the test split will come from the training data as part of the tensorflow LSTM model call). HINT: Think carefully about how you do your train/validation split--does it make sense to randomize the data?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db3cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load your data into a pandas dataframe here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a7845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create your training and validation sets here\n",
    "\n",
    "#assign size for data subset\n",
    "\n",
    "\n",
    "#take random data subset\n",
    "\n",
    "\n",
    "#split data subset 80/20 for train/validation\n",
    "\n",
    "train_df = ??\n",
    "val_df = ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0a7b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset the indices for cleanliness\n",
    "train_df = train_df.reset_index()\n",
    "val_df = val_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a34258",
   "metadata": {},
   "source": [
    "Next we need to create our input and output sequences. In the lab session this week, we used an LSTM model to make a binary prediction, but LSTM models are very flexible in what they can output: we can also use them to predict a single real-numbered output (we can even use them to predict a sequence of outputs). Here we will train a model to predict a single real-numbered output such that we can compare our model directly to the linear regression model from last week.\n",
    "\n",
    "**TODO: Create a nested list structure for the training data, with a sequence of GAP measurements as the input and the GAP measurement at your predictive horizon as your expected output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b5117",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_arrays = []\n",
    "seq_labs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b6475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll start out with a 30 minute input sequence and a 5 minute predictive horizon\n",
    "# we don't need to work in seconds this time, since we'll just use the indices instead of a unix timestamp\n",
    "seq_length = 30\n",
    "ph = 5\n",
    "\n",
    "feat_cols = ['Global_active_power']\n",
    "\n",
    "#create list of sequence length GAP readings\n",
    "\n",
    "\n",
    "#convert to numpy arrays and floats to appease keras/tensorflow        \n",
    "seq_arrays = np.array(seq_arrays, dtype = object).astype(np.float32)\n",
    "seq_labs = np.array(seq_labs, dtype = object).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5c2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(seq_arrays.shape == (len(train_df)-seq_length-ph,seq_length, len(feat_cols)))\n",
    "assert(seq_labs.shape == (len(train_df)-seq_length-ph,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c46a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_arrays.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb66dc2",
   "metadata": {},
   "source": [
    "**Q: What is the function of the assert statements in the above cell? Why do we use assertions in our code?**\n",
    "\n",
    "A: \n",
    "\n",
    "## Model Training\n",
    "\n",
    "We will begin with a model architecture very similar to the model we built in the lab session. We will have two LSTM layers, with 5 and 3 hidden units respectively, and we will apply dropout after each LSTM layer. However, we will use a LINEAR final layer and MSE for our loss function, since our output is continuous instead of binary.\n",
    "\n",
    "**TODO: Fill in all values marked with a ?? in the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a57c132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to save model\n",
    "model_path = 'LSTM_model1.keras'\n",
    "\n",
    "# build the network\n",
    "nb_features = ??\n",
    "nb_out = ??\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#add first LSTM layer\n",
    "model.add(LSTM(\n",
    "         input_shape=(??, ??),\n",
    "         units=??, \n",
    "         return_sequences=True))\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "# add second LSTM layer\n",
    "model.add(LSTM(\n",
    "          units=??,\n",
    "          return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=??))\n",
    "model.add(Activation(??))\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer,metrics=['mse'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# fit the network\n",
    "history = model.fit(??, ??, epochs=100, batch_size=500, validation_split=0.05, verbose=2,\n",
    "          callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min'),\n",
    "                       keras.callbacks.ModelCheckpoint(model_path,monitor='val_loss', save_best_only=True, mode='min', verbose=0)]\n",
    "          )\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5dd990",
   "metadata": {},
   "source": [
    "We will use the code from the book to visualize our training progress and model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d4d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for Loss/MSE\n",
    "fig_acc = plt.figure(figsize=(10, 10))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss/MSE')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "fig_acc.savefig(\"LSTM_loss1.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0522509",
   "metadata": {},
   "source": [
    "## Validating our model\n",
    "\n",
    "Now we need to create our simulated streaming validation set to test our model \"in production\". With our linear regression models, we were able to begin making predictions with only two datapoints, but the LSTM model requires an input sequence of *seq_length* to make a prediction. We can get around this limitation by \"padding\" our inputs when they are too short.\n",
    "\n",
    "**TODO: create a nested list structure for the validation data, with a sequence of GAP measurements as the input and the GAP measurement at your predictive horizon as your expected output. Begin your predictions after only two GAP measurements are available, and check out [this keras function](https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences) to automatically pad sequences that are too short.**\n",
    "\n",
    "**Q: Describe the pad_sequences function and how it manages sequences of variable length. What does the \"padding\" argument determine, and which setting makes the most sense for our use case here?**\n",
    "\n",
    "A: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ea44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_arrays = []\n",
    "val_labs = []\n",
    "\n",
    "#create list of GAP readings starting with a minimum of two readings\n",
    "\n",
    "\n",
    "# use the pad_sequences function on your input sequences\n",
    "# remember that we will later want our datatype to be np.float32 \n",
    "val_arrays =    \n",
    "        \n",
    "#convert labels to numpy arrays and floats to appease keras/tensorflow\n",
    "val_labs = np.array(val_labs, dtype = object).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a553f881",
   "metadata": {},
   "source": [
    "We will now run this validation data through our LSTM model and visualize its performance like we did on the linear regression data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test = model.evaluate(val_arrays, val_labs, verbose=2)\n",
    "print('\\nMSE: {}'.format(scores_test[1]))\n",
    "\n",
    "y_pred_test = model.predict(val_arrays)\n",
    "y_true_test = val_labs\n",
    "\n",
    "test_set = pd.DataFrame(y_pred_test)\n",
    "test_set.to_csv('submit_test.csv', index = None)\n",
    "\n",
    "# Plot the predicted data vs. the actual data\n",
    "# we will limit our plot to the first 500 predictions for better visualization\n",
    "fig_verify = plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_pred_test[-500:], label = 'Predicted Value')\n",
    "plt.plot(y_true_test[-500:], label = 'Actual Value')\n",
    "plt.title('Global Active Power Prediction - Last 500 Points', fontsize=22, fontweight='bold')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('row')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig_verify.savefig(\"model_regression_verify.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5fcbe0",
   "metadata": {},
   "source": [
    "**Q: How did your model perform? What can you tell about the model from the loss curves? What could we do to try to improve the model?**\n",
    "\n",
    "A: \n",
    "\n",
    "\n",
    "## Model Optimization\n",
    "\n",
    "Now it's your turn to build an LSTM-based model in hopes of improving performance on this training set. Changes that you might consider include:\n",
    "\n",
    "- Add more variables to the input sequences\n",
    "- Change the optimizer and/or adjust the learning rate\n",
    "- Change the sequence length and/or the predictive horizon\n",
    "- Change the number of hidden layers in each of the LSTM layers\n",
    "- Change the model architecture altogether--think about adding convolutional layers, linear layers, additional regularization, creating embeddings for the input data, changing the loss function, etc.\n",
    "\n",
    "There isn't any minimum performance increase or number of changes that need to be made, but I want to see that you have tried some different things. Remember that building and optimizing deep learning networks is an art and can be very difficult, so don't make yourself crazy trying to optimize for this assignment.\n",
    "\n",
    "**Q: What changes are you going to try with your model? Why do you think these changes could improve model performance?**\n",
    "\n",
    "A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50afded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# play with your ideas for optimization here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22b9a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show me how one or two of your different models perform \n",
    "# using the code from the \"Validating our model\" section above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ccb037",
   "metadata": {},
   "source": [
    "**Q: How did your model changes affect performance on the validation data? Why do you think they were/were not effective? If you were trying to optimize for production, what would you try next?**\n",
    "\n",
    "A: \n",
    "\n",
    "**Q: How did the models that you built in this assignment compare to the linear regression model from last week? Think about model performance and other IoT device considerations; Which model would you choose to use in an IoT system that predicts GAP for a single household with a 5-minute predictive horizon, and why?**\n",
    "\n",
    "A: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
